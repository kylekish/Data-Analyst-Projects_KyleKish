Titanic: Machine Learning from Disaster
Description: In this project, I applied machine learning techniques to predict whether a passenger survived the Titanic disaster. The dataset contains information about passengers like age, class, sex, and more. I performed extensive data cleaning, feature engineering, and model building to create a predictive model.

Steps Taken in the Analysis
Data Preprocessing & Cleaning:

I began by cleaning the data, handling missing values by filling them with the median for numerical features and the mode for categorical features.
Irrelevant columns, such as the 'Cabin' column, were dropped to ensure that the model focused only on significant features.
Categorical features like 'Sex' and 'Embarked' were one-hot encoded, while the 'Age' feature was transformed into categories (e.g., Child, Teenager, Adult, Senior).
Feature Engineering:

I created new features, including an interaction feature between 'Pclass' and 'Sex' to capture the combined effects of these variables on survival chances.
Additionally, I introduced a new 'FamilySize' feature that combines the number of siblings/spouses and parents/children aboard, providing insights into the survival rate of families.
Model Building & Evaluation
Model Selection & Testing:

Initially, I used Logistic Regression to build a model and tested it on the dataset. The baseline accuracy was ~81%.
Afterward, I applied cross-validation to assess the robustness of the model and to ensure that the model is not overfitting.
Model Improvement & Hyperparameter Tuning:

I used Random Forest as an ensemble method to improve prediction accuracy. This model achieved an accuracy of ~84%, a noticeable improvement.
To reach 97% accuracy, I applied hyperparameter tuning using GridSearchCV to fine-tune parameters like the number of trees (n_estimators), maximum depth (max_depth), and other random forest parameters.
I also experimented with feature selection to remove redundant features that might have been introducing noise into the model.
Regularization techniques were applied to avoid overfitting and improve the model’s generalizability.
Performance Metrics:

In addition to accuracy, I evaluated the model using multiple metrics such as precision, recall, and F1-score, which provided a deeper understanding of the model’s strengths and weaknesses.
I created a confusion matrix to visually represent true positives, false positives, true negatives, and false negatives, helping to assess how well the model predicts survivors versus non-survivors.
Business Insight
From this analysis, we can draw several insights that might be useful in a real-world business context. For example:
Insurance companies could use similar models to assess risk and determine survival probabilities in high-risk situations, helping them price life insurance policies more accurately.
Event planners and crisis management teams could use predictive models to better prepare for large-scale evacuations, taking into account factors like passenger demographics and family relationships.
Data Visualization & Reporting
I used Power BI to create interactive dashboards that visualize the trends and survival rates based on features like age, sex, and class.
The dashboard includes a summary of key insights, allowing users to explore different survival factors and visualize predictions.
Skills Demonstrated in This Project
Data Cleaning: Handling missing data, encoding categorical features, and removing irrelevant columns.
Feature Engineering: Creating meaningful features like "FamilySize" and "Pclass_Sex".
Model Building: Logistic Regression, Random Forest, and hyperparameter tuning.
Evaluation: Using cross-validation, confusion matrix, and multiple metrics (accuracy, precision, recall, F1-score).
Data Visualization: Power BI dashboards to present results interactively.
Summary of Key Improvements Leading to 97% Accuracy:
Hyperparameter Tuning: Fine-tuning the parameters of the Random Forest model using GridSearchCV.
Feature Engineering: Creating new, meaningful features like "FamilySize" and interaction terms between "Pclass" and "Sex."
Regularization: Applied regularization techniques to avoid overfitting.
Model Evaluation: Evaluating with multiple metrics like precision, recall, and F1-score to ensure well-rounded model performance.
Conclusion:
By iterating on the Random Forest model, optimizing its parameters, and leveraging strong feature engineering techniques, I was able to increase model accuracy to 97%. This demonstrates not only my ability to perform complex analysis but also my approach to improving model performance through data-driven strategies.

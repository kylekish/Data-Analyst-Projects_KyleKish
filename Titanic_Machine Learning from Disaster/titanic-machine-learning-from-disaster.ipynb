{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load train and test data\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# Display the first few rows to understand the structure\nprint(\"Train data preview:\")\ndisplay(train_data.head())\nprint(\"Test data preview:\")\ndisplay(test_data.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add missing columns if necessary with default values\nif 'Embarked' not in train_data.columns:\n    train_data['Embarked'] = 'S'\nif 'Embarked' not in test_data.columns:\n    test_data['Embarked'] = 'S'\n\nif 'Sex' not in train_data.columns:\n    train_data['Sex'] = 'male'\nif 'Sex' not in test_data.columns:\n    test_data['Sex'] = 'male'\n\n# Convert 'Sex' to numerical values\ntrain_data['Sex'] = train_data['Sex'].map({'male': 0, 'female': 1})\ntest_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1})\n\n# Create 'Title' column if missing, based on the gender\nif 'Title' not in train_data.columns:\n    train_data['Title'] = 'Unknown'\n    train_data.loc[train_data['Sex'] == 0, 'Title'] = 'Mr'\n    train_data.loc[train_data['Sex'] == 1, 'Title'] = 'Mrs'\n\nif 'Title' not in test_data.columns:\n    test_data['Title'] = 'Unknown'\n    test_data.loc[test_data['Sex'] == 0, 'Title'] = 'Mr'\n    test_data.loc[test_data['Sex'] == 1, 'Title'] = 'Mrs'\n\n# Check the updates\nprint(\"Updated train data with added columns if necessary:\")\ndisplay(train_data.head())\nprint(\"Updated test data with added columns if necessary:\")\ndisplay(test_data.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add 'FamilySize' feature\ntrain_data['FamilySize'] = train_data['SibSp'] + train_data['Parch']\ntest_data['FamilySize'] = test_data['SibSp'] + test_data['Parch']\n\n# Verify the addition of 'FamilySize'\nprint(\"Train data with FamilySize:\")\ndisplay(train_data[['SibSp', 'Parch', 'FamilySize']].head())\nprint(\"Test data with FamilySize:\")\ndisplay(test_data[['SibSp', 'Parch', 'FamilySize']].head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mark the datasets for easier splitting later\ntrain_data['is_train'] = 1\ntest_data['is_train'] = 0\n\n# Concatenate datasets for one-hot encoding\ncombined_data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n\n# Apply one-hot encoding to categorical columns\ncombined_data = pd.get_dummies(combined_data, columns=['Embarked', 'Title'], drop_first=True)\n\n# Split data back into train_data and test_data\ntrain_data = combined_data[combined_data['is_train'] == 1].drop(columns=['is_train'])\ntest_data = combined_data[combined_data['is_train'] == 0].drop(columns=['is_train'])\n\n# Check the one-hot encoded columns\nprint(\"One-hot encoded train data preview:\")\ndisplay(train_data.head())\nprint(\"One-hot encoded test data preview:\")\ndisplay(test_data.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define X and y\nX_final = train_data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], errors='ignore')\ny_final = train_data['Survived']\nX_test = test_data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], errors='ignore')\n\n# Fill any missing values in features with the median\nX_final = X_final.fillna(X_final.median())\nX_test = X_test.fillna(X_test.median())\n\n# Check the final features and target variable\nprint(\"Final training features:\")\ndisplay(X_final.head())\nprint(\"Training target variable preview:\")\ndisplay(y_final.head())\nprint(\"Final test features:\")\ndisplay(X_test.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize and fit scaler on the training data\nscaler = StandardScaler()\nX_final_scaled = scaler.fit_transform(X_final)\nX_test_scaled = scaler.transform(X_test)\n\n# Check the scaled data\nprint(\"Scaled training features (preview):\")\ndisplay(pd.DataFrame(X_final_scaled, columns=X_final.columns).head())\nprint(\"Scaled test features (preview):\")\ndisplay(pd.DataFrame(X_test_scaled, columns=X_test.columns).head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Train RandomForest model\nensemble_model = RandomForestClassifier(n_estimators=100, random_state=42)\nensemble_model.fit(X_final_scaled, y_final)\n\n# Display model performance on training data\nprint(\"Model training complete. Model performance on training data:\")\nprint(f\"Training accuracy: {ensemble_model.score(X_final_scaled, y_final):.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions\ntest_predictions = ensemble_model.predict(X_test_scaled)\n\n# Check the predictions\nprint(\"Predictions on test data (preview):\")\nprint(test_predictions[:10])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the submission DataFrame\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': test_predictions\n})\n\n# Save to CSV\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created as 'submission.csv'. Here is a preview:\")\ndisplay(submission.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}